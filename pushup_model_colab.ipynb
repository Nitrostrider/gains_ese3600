{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushup Posture & Phase Classification Model\n",
    "\n",
    "Multi-task CNN-LSTM model for classifying pushup phase and posture from IMU data.\n",
    "\n",
    "**Labels:**\n",
    "- **Phase**: top, moving-down, bottom, moving-up, not-in-pushup\n",
    "- **Posture**: good-form, hips-sagging, hips-high, partial-rom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Dataset (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Upload your pushup_data_YYYYMMDD_HHMMSS.json files\nfrom google.colab import files\n\nprint(\"Please upload your pushup dataset JSON file(s)...\")\nprint(\"You can select MULTIPLE files if you have data from different sessions\")\nuploaded = files.upload()\n\n# Get all uploaded filenames\nDATA_FILES = list(uploaded.keys())\nprint(f\"\\nUploaded {len(DATA_FILES)} file(s):\")\nfor filename in DATA_FILES:\n    print(f\"  - {filename}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load and combine all JSON files\nall_sessions = []\n\nfor data_file in DATA_FILES:\n    with open(data_file, 'r') as f:\n        data = json.load(f)\n        all_sessions.extend(data['sessions'])\n    print(f\"Loaded {len(data['sessions'])} sessions from {data_file}\")\n\nprint(f\"\\nTotal sessions across all files: {len(all_sessions)}\")\n\n# Show first session structure\nif len(all_sessions) > 0:\n    print(f\"\\nFirst session structure:\")\n    first_session = all_sessions[0]\n    print(f\"  Phase: {first_session['phase_label']}\")\n    print(f\"  Posture: {first_session['posture_label']}\")\n    print(f\"  Samples: {len(first_session['imu_data'])}\")\n    print(f\"  Duration: {first_session['duration']:.2f}s\")\n\n    # Count label distributions\n    phase_counts = {}\n    posture_counts = {}\n\n    for session in all_sessions:\n        phase = session['phase_label']\n        posture = session['posture_label']\n        phase_counts[phase] = phase_counts.get(phase, 0) + 1\n        posture_counts[posture] = posture_counts.get(posture, 0) + 1\n\n    print(f\"\\nPhase distribution: {phase_counts}\")\n    print(f\"Posture distribution: {posture_counts}\")\nelse:\n    print(\"Warning: No sessions found!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing - Sliding Window Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Hyperparameters\nWINDOW_SIZE = 100  # samples per window (~1-2 seconds at 50-100 Hz)\nSTRIDE = 25        # overlap of 75%\nSAMPLING_RATE = 100  # Hz (adjust based on your data)\n\ndef create_windows(imu_data, window_size, stride):\n    \"\"\"\n    Create sliding windows from IMU time series.\n    \n    Args:\n        imu_data: List of dicts with keys 'ax', 'ay', 'az', 'gx', 'gy', 'gz'\n        window_size: Number of samples per window\n        stride: Step size between windows\n    \n    Returns:\n        np.array of shape [num_windows, window_size, 6]\n    \"\"\"\n    # Convert to numpy array [samples, 6]\n    data_array = np.array([\n        [sample['ax'], sample['ay'], sample['az'],\n         sample['gx'], sample['gy'], sample['gz']]\n        for sample in imu_data\n    ])\n    \n    windows = []\n    for i in range(0, len(data_array) - window_size + 1, stride):\n        window = data_array[i:i+window_size]\n        windows.append(window)\n    \n    return np.array(windows)\n\n# Process all sessions from all files\nX_windows = []\ny_phase = []\ny_posture = []\n\nfor session in all_sessions:\n    windows = create_windows(session['imu_data'], WINDOW_SIZE, STRIDE)\n    \n    # Each window inherits the session's labels\n    for window in windows:\n        X_windows.append(window)\n        y_phase.append(session['phase_label'])\n        y_posture.append(session['posture_label'])\n\nX = np.array(X_windows)\nprint(f\"\\nCreated {len(X)} windows of shape {X.shape}\")\nprint(f\"Expected shape: [num_windows, {WINDOW_SIZE}, 6]\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to integers\n",
    "phase_encoder = LabelEncoder()\n",
    "posture_encoder = LabelEncoder()\n",
    "\n",
    "y_phase_encoded = phase_encoder.fit_transform(y_phase)\n",
    "y_posture_encoded = posture_encoder.fit_transform(y_posture)\n",
    "\n",
    "# Convert to categorical (one-hot)\n",
    "num_phase_classes = len(phase_encoder.classes_)\n",
    "num_posture_classes = len(posture_encoder.classes_)\n",
    "\n",
    "y_phase_cat = keras.utils.to_categorical(y_phase_encoded, num_phase_classes)\n",
    "y_posture_cat = keras.utils.to_categorical(y_posture_encoded, num_posture_classes)\n",
    "\n",
    "print(f\"Phase classes ({num_phase_classes}): {phase_encoder.classes_}\")\n",
    "print(f\"Posture classes ({num_posture_classes}): {posture_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80/20)\n",
    "X_train, X_test, y_phase_train, y_phase_test, y_posture_train, y_posture_test = train_test_split(\n",
    "    X, y_phase_cat, y_posture_cat, test_size=0.2, random_state=42, stratify=y_phase_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"Input shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and std on training data\n",
    "# Shape: [window_size, 6] -> compute per-channel stats\n",
    "mean = X_train.reshape(-1, 6).mean(axis=0)\n",
    "std = X_train.reshape(-1, 6).std(axis=0)\n",
    "\n",
    "# Normalize\n",
    "X_train_norm = (X_train - mean) / (std + 1e-8)\n",
    "X_test_norm = (X_test - mean) / (std + 1e-8)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")\n",
    "\n",
    "# Save normalization parameters\n",
    "norm_params = {\n",
    "    'mean': mean.tolist(),\n",
    "    'std': std.tolist()\n",
    "}\n",
    "with open('norm_params.json', 'w') as f:\n",
    "    json.dump(norm_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Build Multi-Task Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multitask_model(input_shape, num_phase_classes, num_posture_classes):\n",
    "    \"\"\"\n",
    "    CNN-LSTM multi-task model for phase and posture classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - 1D CNN layers for feature extraction\n",
    "    - LSTM layer for temporal modeling\n",
    "    - Two output heads (phase, posture)\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=input_shape, name='imu_input')\n",
    "    \n",
    "    # CNN feature extraction\n",
    "    x = layers.Conv1D(32, kernel_size=5, activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Conv1D(64, kernel_size=5, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM temporal modeling\n",
    "    x = layers.LSTM(64, return_sequences=False)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Shared dense layer\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output heads\n",
    "    phase_output = layers.Dense(num_phase_classes, activation='softmax', name='phase')(x)\n",
    "    posture_output = layers.Dense(num_posture_classes, activation='softmax', name='posture')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=[phase_output, posture_output])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_multitask_model(\n",
    "    input_shape=(WINDOW_SIZE, 6),\n",
    "    num_phase_classes=num_phase_classes,\n",
    "    num_posture_classes=num_posture_classes\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 8.1 Alternative: TFLite Micro Compatible Model (No LSTM)\n\n**IMPORTANT:** The LSTM model above won't work on ESP32 because TFLite Micro doesn't support LSTM ops.\n\nUse this simpler CNN-only model instead:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def build_tflite_micro_compatible_model(input_shape, num_phase_classes, num_posture_classes):\n    \"\"\"\n    CNN-only model compatible with TFLite Micro (no LSTM).\n    \n    Uses only 1D convolutions, pooling, and dense layers.\n    All ops are supported on ESP32.\n    \"\"\"\n    inputs = keras.Input(shape=input_shape, name='imu_input')\n    \n    # 1D CNN feature extraction (deeper to compensate for no LSTM)\n    x = layers.Conv1D(32, kernel_size=5, activation='relu', padding='same')(inputs)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    x = layers.Dropout(0.3)(x)\n    \n    x = layers.Conv1D(64, kernel_size=5, activation='relu', padding='same')(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    x = layers.Dropout(0.3)(x)\n    \n    x = layers.Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    x = layers.Dropout(0.3)(x)\n    \n    # Global pooling to reduce to fixed size\n    x = layers.GlobalAveragePooling1D()(x)\n    \n    # Dense layers\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    \n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    \n    # Output heads\n    phase_output = layers.Dense(num_phase_classes, activation='softmax', name='phase')(x)\n    posture_output = layers.Dense(num_posture_classes, activation='softmax', name='posture')(x)\n    \n    model = keras.Model(inputs=inputs, outputs=[phase_output, posture_output])\n    \n    return model\n\n# Build TFLite Micro compatible model\nprint(\"Building TFLite Micro compatible model (CNN-only, no LSTM)...\")\nmodel_micro = build_tflite_micro_compatible_model(\n    input_shape=(WINDOW_SIZE, 6),\n    num_phase_classes=num_phase_classes,\n    num_posture_classes=num_posture_classes\n)\n\nmodel_micro.summary()\n\nprint(\"\\nThis model uses ONLY TFLite-compatible ops:\")\nprint(\"- Conv1D\")\nprint(\"- MaxPooling1D\")  \nprint(\"- GlobalAveragePooling1D\")\nprint(\"- Dense\")\nprint(\"- Dropout (removed during conversion)\")\nprint(\"\\nIt will work on ESP32 TFLite Micro!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# IMPORTANT: Use the TFLite Micro compatible model!\n# Change this line to use model_micro instead of model\n# model = model_micro\n\n# For now, train the LSTM model for comparison\n# But remember: You MUST use model_micro for ESP32 deployment!\n\n# Compile with separate losses for each output\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss={\n        'phase': 'categorical_crossentropy',\n        'posture': 'categorical_crossentropy'\n    },\n    metrics={\n        'phase': ['accuracy'],\n        'posture': ['accuracy']\n    },\n    loss_weights={'phase': 1.0, 'posture': 1.0}\n)\n\n# Train\nhistory = model.fit(\n    X_train_norm,\n    {'phase': y_phase_train, 'posture': y_posture_train},\n    validation_data=(\n        X_test_norm,\n        {'phase': y_phase_test, 'posture': y_posture_test}\n    ),\n    epochs=50,\n    batch_size=32,\n    verbose=1\n)\n\nprint(\"\\nTraining complete!\")\nprint(\"\\n⚠️  WARNING: This LSTM model won't work on ESP32!\")\nprint(\"For ESP32 deployment, retrain using model_micro instead.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Phase loss\n",
    "axes[0, 0].plot(history.history['phase_loss'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_phase_loss'], label='Val')\n",
    "axes[0, 0].set_title('Phase Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Phase accuracy\n",
    "axes[0, 1].plot(history.history['phase_accuracy'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_phase_accuracy'], label='Val')\n",
    "axes[0, 1].set_title('Phase Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Posture loss\n",
    "axes[1, 0].plot(history.history['posture_loss'], label='Train')\n",
    "axes[1, 0].plot(history.history['val_posture_loss'], label='Val')\n",
    "axes[1, 0].set_title('Posture Loss')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Posture accuracy\n",
    "axes[1, 1].plot(history.history['posture_accuracy'], label='Train')\n",
    "axes[1, 1].plot(history.history['val_posture_accuracy'], label='Val')\n",
    "axes[1, 1].set_title('Posture Accuracy')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "results = model.evaluate(X_test_norm, {'phase': y_phase_test, 'posture': y_posture_test}, verbose=0)\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Phase Accuracy: {results[3]:.4f}\")\n",
    "print(f\"Posture Accuracy: {results[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as .h5 file\n",
    "MODEL_FILE = 'pushup_model.h5'\n",
    "model.save(MODEL_FILE)\n",
    "print(f\"Saved model to {MODEL_FILE}\")\n",
    "\n",
    "# Save label encoders\n",
    "metadata = {\n",
    "    'phase_classes': phase_encoder.classes_.tolist(),\n",
    "    'posture_classes': posture_encoder.classes_.tolist(),\n",
    "    'window_size': WINDOW_SIZE,\n",
    "    'stride': STRIDE,\n",
    "    'sampling_rate': SAMPLING_RATE,\n",
    "    'num_phase_classes': num_phase_classes,\n",
    "    'num_posture_classes': num_posture_classes\n",
    "}\n",
    "\n",
    "with open('model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Saved metadata to model_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Convert to TensorFlow Lite\n",
    "\n",
    "### 12.1 Float32 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export as TensorFlow SavedModel format first (for TFLite conversion)\nSAVED_MODEL_DIR = 'saved_model'\nmodel.export(SAVED_MODEL_DIR)\n\n# Convert to TFLite (Float32)\nconverter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n\n# IMPORTANT: TFLite Micro on ESP32 doesn't support SELECT_TF_OPS\n# We need to use only built-in TFLite ops\n# This means we CANNOT use native LSTM layers on embedded devices\n\nprint(\"WARNING: This model uses LSTM which requires SELECT_TF_OPS\")\nprint(\"These ops are NOT supported on TFLite Micro (ESP32)\")\nprint(\"Converting anyway for reference, but you'll need to simplify the model\")\nprint(\"Recommendation: Replace LSTM with 1D Conv layers or SimpleRNN\")\n\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS,  # Use only TFLite built-in ops\n]\n\ntry:\n    tflite_model_float = converter.convert()\n    \n    # Save float32 model\n    FLOAT_MODEL_FILE = 'pushup_model_float32.tflite'\n    with open(FLOAT_MODEL_FILE, 'wb') as f:\n        f.write(tflite_model_float)\n    \n    float_size = len(tflite_model_float) / 1024\n    print(f\"\\nFloat32 TFLite model size: {float_size:.2f} KB\")\n    print(f\"Saved to {FLOAT_MODEL_FILE}\")\nexcept Exception as e:\n    print(f\"\\nERROR during conversion: {e}\")\n    print(\"\\nThe model architecture is not compatible with TFLite Micro.\")\n    print(\"You need to rebuild the model without LSTM layers.\")\n    print(\"See section 8.1 below for a SimpleRNN-based alternative.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 INT8 Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representative dataset for quantization\n",
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        # Use random samples from training data\n",
    "        idx = np.random.randint(0, len(X_train_norm))\n",
    "        sample = X_train_norm[idx:idx+1].astype(np.float32)\n",
    "        yield [sample]\n",
    "\n",
    "# Convert to TFLite with INT8 quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_quantized = converter.convert()\n",
    "\n",
    "print(\"INT8 quantization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Save Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model\n",
    "QUANTIZED_MODEL_FILE = 'pushup_model_quantized.tflite'\n",
    "with open(QUANTIZED_MODEL_FILE, 'wb') as f:\n",
    "    f.write(tflite_model_quantized)\n",
    "\n",
    "quantized_size = len(tflite_model_quantized) / 1024\n",
    "compression_ratio = float_size / quantized_size\n",
    "\n",
    "print(f\"\\nQuantized TFLite model size: {quantized_size:.2f} KB\")\n",
    "print(f\"Compression ratio: {compression_ratio:.2f}x\")\n",
    "print(f\"Saved to {QUANTIZED_MODEL_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test TFLite Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tflite_model(tflite_model_path, X_test, y_phase_test, y_posture_test, is_quantized=False):\n",
    "    \"\"\"\n",
    "    Evaluate TFLite model accuracy on test set.\n",
    "    \"\"\"\n",
    "    # Load TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Get input/output scales and zero points for quantized model\n",
    "    input_scale, input_zero_point = input_details[0]['quantization']\n",
    "    \n",
    "    phase_predictions = []\n",
    "    posture_predictions = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        input_data = X_test[i:i+1].astype(np.float32)\n",
    "        \n",
    "        # Quantize input if needed\n",
    "        if is_quantized:\n",
    "            input_data = input_data / input_scale + input_zero_point\n",
    "            input_data = input_data.astype(np.int8)\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        # Get outputs (phase and posture)\n",
    "        phase_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "        posture_output = interpreter.get_tensor(output_details[1]['index'])[0]\n",
    "        \n",
    "        # Dequantize outputs if needed\n",
    "        if is_quantized:\n",
    "            phase_scale, phase_zero_point = output_details[0]['quantization']\n",
    "            posture_scale, posture_zero_point = output_details[1]['quantization']\n",
    "            phase_output = (phase_output.astype(np.float32) - phase_zero_point) * phase_scale\n",
    "            posture_output = (posture_output.astype(np.float32) - posture_zero_point) * posture_scale\n",
    "        \n",
    "        phase_predictions.append(np.argmax(phase_output))\n",
    "        posture_predictions.append(np.argmax(posture_output))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    phase_true = np.argmax(y_phase_test, axis=1)\n",
    "    posture_true = np.argmax(y_posture_test, axis=1)\n",
    "    \n",
    "    phase_accuracy = np.mean(np.array(phase_predictions) == phase_true)\n",
    "    posture_accuracy = np.mean(np.array(posture_predictions) == posture_true)\n",
    "    \n",
    "    return phase_accuracy, posture_accuracy\n",
    "\n",
    "# Test Float32 model\n",
    "print(\"Evaluating Float32 TFLite model...\")\n",
    "float_phase_acc, float_posture_acc = evaluate_tflite_model(\n",
    "    FLOAT_MODEL_FILE, X_test_norm, y_phase_test, y_posture_test, is_quantized=False\n",
    ")\n",
    "print(f\"  Phase Accuracy: {float_phase_acc:.4f}\")\n",
    "print(f\"  Posture Accuracy: {float_posture_acc:.4f}\")\n",
    "\n",
    "# Test Quantized model\n",
    "print(\"\\nEvaluating INT8 Quantized TFLite model...\")\n",
    "quant_phase_acc, quant_posture_acc = evaluate_tflite_model(\n",
    "    QUANTIZED_MODEL_FILE, X_test_norm, y_phase_test, y_posture_test, is_quantized=True\n",
    ")\n",
    "print(f\"  Phase Accuracy: {quant_phase_acc:.4f}\")\n",
    "print(f\"  Posture Accuracy: {quant_posture_acc:.4f}\")\n",
    "\n",
    "# Accuracy drop\n",
    "print(\"\\nAccuracy drop due to quantization:\")\n",
    "print(f\"  Phase: {(float_phase_acc - quant_phase_acc)*100:.2f}%\")\n",
    "print(f\"  Posture: {(float_posture_acc - quant_posture_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Convert TFLite to C Array (.cc file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use xxd to convert binary to C array\n",
    "CC_MODEL_FILE = 'pushup_model_quantized.cc'\n",
    "\n",
    "print(f\"Converting {QUANTIZED_MODEL_FILE} to C array...\")\n",
    "\n",
    "# Run xxd command\n",
    "result = subprocess.run(\n",
    "    ['xxd', '-i', QUANTIZED_MODEL_FILE],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    # Write output to .cc file\n",
    "    with open(CC_MODEL_FILE, 'w') as f:\n",
    "        f.write(result.stdout)\n",
    "    \n",
    "    print(f\"Converted {QUANTIZED_MODEL_FILE} to {CC_MODEL_FILE}\")\n",
    "    print(f\"Model can now be embedded in Arduino/ESP32 firmware\")\n",
    "    \n",
    "    # Show first few lines\n",
    "    with open(CC_MODEL_FILE, 'r') as f:\n",
    "        lines = f.readlines()[:10]\n",
    "    print(\"\\nFirst 10 lines of .cc file:\")\n",
    "    print(''.join(lines))\n",
    "else:\n",
    "    print(f\"Error running xxd: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Download All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all generated files\n",
    "from google.colab import files\n",
    "\n",
    "files_to_download = [\n",
    "    MODEL_FILE,                # pushup_model.h5\n",
    "    'model_metadata.json',     # Label encoders and config\n",
    "    FLOAT_MODEL_FILE,          # Float32 TFLite\n",
    "    QUANTIZED_MODEL_FILE,      # INT8 quantized TFLite\n",
    "    CC_MODEL_FILE              # C array for embedded deployment\n",
    "]\n",
    "\n",
    "print(\"Downloading files...\")\n",
    "for filename in files_to_download:\n",
    "    if os.path.exists(filename):\n",
    "        files.download(filename)\n",
    "        print(f\"  Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"  Warning: {filename} not found\")\n",
    "\n",
    "print(\"\\nAll files downloaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}